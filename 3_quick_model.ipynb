{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a56295cf",
   "metadata": {},
   "source": [
    "## Features:\n",
    "\n",
    "### Client:\n",
    "\n",
    "- Client_id: Unique id for client\n",
    "- District: District where the client is\n",
    "- Client_catg: Category client belongs to\n",
    "- Region: Area where the client is\n",
    "- Creation_date: Date client joined\n",
    "- Target: fraud:1 , not fraud: 0\n",
    "\n",
    "\n",
    "### Invoice data\n",
    "\n",
    "- Client_id: Unique id for the client\n",
    "- Invoice_date: Date of the invoice\n",
    "- Tarif_type: Type of tax\n",
    "- Counter_number:\n",
    "- Counter_statue: takes up to 5 values such as working fine, not working, on hold statue, ect\n",
    "- Counter_code:\n",
    "- Reading_remarque: notes that the STEG agent takes during his visit to the client (e.g: If the counter shows something wrong, the agent gives a bad score)\n",
    "- Counter_coefficient: An additional coefficient to be added when standard consumption is exceeded\n",
    "- Consommation_level_1: Consumption_level_1\n",
    "- Consommation_level_2: Consumption_level_2\n",
    "- Consommation_level_3: Consumption_level_3\n",
    "- Consommation_level_4: Consumption_level_4\n",
    "- Old_index: Old index\n",
    "- New_index: New index\n",
    "- Months_number: Month number\n",
    "- Counter_type: Type of counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76a0645",
   "metadata": {},
   "source": [
    "## Some findings\n",
    "\n",
    "- the \"test\" = \"competition\" set (no targets there). Therefore must split the \"train\" set into train/test sets\n",
    "\n",
    "- must not aggregate to make a shorter table with customers. Instead predict on TRANSACTIONS. (df.groupby('client_id').nunique())\n",
    "\n",
    "- the proportion of positives is higher in the merged \"transactions\" table than the proportion of positives in the \"clients\" table (0.06 / 0.08).  So you can treat that as \"perturbation\" of positives in order to increase the number of positives (where they are scarse). I.e. this is one more argument in the favour of predicting on transactions  and then aggregating them to get a prediction for a particular customer.\n",
    "\n",
    "- the 'months_number' column does not contain actual months. These values do not correspond to the 'creation_date' or 'invoice_date' columns.  Either keep this columns without any transformation or scaling or delete it completeley. Because the test set contains this kidn of wierd values too.\n",
    "\n",
    "- the features  ['consommation_level_1', 'consommation_level_2', 'consommation_level_3', 'consommation_level_4']   are not very promising (in tearms of building univariate logistic regression on them)\n",
    "\n",
    "- columns 'counter_statue'  is supposed to be integers [0-5] but is of mixed type (object) with some bogus values.  Convert to int, drop the rows with values > 5, because the test set doesnt have any bad values in this column - only the valid integers from 0 to 5\n",
    "\n",
    "- search for a decent baseline model didn't give decent results. Try non-deterministic baseline model based on the prior (i.e. the proportion of positives in the population)\n",
    "\n",
    "- eventually agreed to predict transactions (and not fraudulent clients)\n",
    "\n",
    "- rule-based baseline model on two rules (2005, higher consumption)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "858f48bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from sklearn.metrics import fbeta_score, confusion_matrix, recall_score, precision_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76bb87f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature preprocessing functions\n",
    "\n",
    "def preprocess(feature, data):\n",
    "    functions = {'counter_statue': preprocess_counter_statue}\n",
    "    feature = feature if type(feature) is str else data.name if type(data) is pd.Series else data.columns[feature]\n",
    "    function = functions[feature]\n",
    "    return function(data)\n",
    "\n",
    "    \n",
    "# preprocess 'counter_statue'\n",
    "def preprocess_counter_statue(data):\n",
    "    col = 'counter_statue'\n",
    "    sr = data[col].astype(str)\n",
    "    mask = sr.isin(list(\"012345\"))\n",
    "    sr[~mask] = sr[mask].mode().values[0]\n",
    "    data[col] = sr.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "882f4079",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = \"data/train/client_train.csv\"\n",
    "path2 = \"data/train/invoice_train.csv\"\n",
    "\n",
    "path3 = \"data/test/client_test.csv\"\n",
    "path4 = \"data/test/invoice_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6746538",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/21/19jhch7d5dd5fjjxf3d06h9m0000gn/T/ipykernel_86539/3557827750.py:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(path2)   # low_memory=False\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "\n",
    "df1 = pd.read_csv(path1)\n",
    "df2 = pd.read_csv(path2)   # low_memory=False\n",
    "\n",
    "df3 = pd.read_csv(path3)\n",
    "df4 = pd.read_csv(path4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01588cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join tables\n",
    "\n",
    "# data from the \"train\" folder (will have to be split into train/test)\n",
    "df = df1.merge(df2, left_on='client_id', right_on='client_id', how='outer')\n",
    "\n",
    "# data from the \"test\" folder (doesn't contain targets)\n",
    "df_test_zindi = df3.merge(df4, left_on='client_id', right_on='client_id', how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce0a0b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not 1000% correct - must use the mode of the train set on the test set\n",
    "preprocess('counter_statue', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4b85a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/21/19jhch7d5dd5fjjxf3d06h9m0000gn/T/ipykernel_86539/1226911683.py:3: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  df['year_created'] = pd.to_datetime(df['creation_date']).dt.year\n"
     ]
    }
   ],
   "source": [
    "# quick and dirty feature engineering \n",
    "\n",
    "df['year_created'] = pd.to_datetime(df['creation_date']).dt.year\n",
    "dates = pd.to_datetime(df['invoice_date'])\n",
    "df['invoice_year'] = dates.dt.year\n",
    "df['invoice_month'] = dates.dt.month\n",
    "df['invoice_weekday'] = dates.dt.weekday\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8239abfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# interaction between the 4 features\\ndf['mult'] = df[['consommation_level_1', 'consommation_level_2',\\n                 'consommation_level_3', 'consommation_level_4']].apply(np.multiply.reduce, axis=1)\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# interaction between the 4 features\n",
    "df['mult'] = df[['consommation_level_1', 'consommation_level_2',\n",
    "                 'consommation_level_3', 'consommation_level_4']].apply(np.multiply.reduce, axis=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e00e8eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "\n",
    "# make random indeces/mask\n",
    "m = len(df)\n",
    "p = .80   # for the train set\n",
    "nx = np.random.permutation(m)[:int(m*p)]\n",
    "mask = np.zeros(m).astype(bool)\n",
    "mask[nx] = True\n",
    "\n",
    "# split\n",
    "df_train = df[mask]\n",
    "df_test = df[~mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62abd42",
   "metadata": {},
   "source": [
    "## TO DISCUSS: Which features to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8c9c5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disrict</th>\n",
       "      <th>client_id</th>\n",
       "      <th>client_catg</th>\n",
       "      <th>region</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>target</th>\n",
       "      <th>invoice_date</th>\n",
       "      <th>tarif_type</th>\n",
       "      <th>counter_number</th>\n",
       "      <th>counter_statue</th>\n",
       "      <th>...</th>\n",
       "      <th>consommation_level_3</th>\n",
       "      <th>consommation_level_4</th>\n",
       "      <th>old_index</th>\n",
       "      <th>new_index</th>\n",
       "      <th>months_number</th>\n",
       "      <th>counter_type</th>\n",
       "      <th>year_created</th>\n",
       "      <th>invoice_year</th>\n",
       "      <th>invoice_month</th>\n",
       "      <th>invoice_weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>31/12/1994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-03-24</td>\n",
       "      <td>11</td>\n",
       "      <td>1335667</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14302</td>\n",
       "      <td>14384</td>\n",
       "      <td>4</td>\n",
       "      <td>ELEC</td>\n",
       "      <td>1994</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>31/12/1994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-03-29</td>\n",
       "      <td>11</td>\n",
       "      <td>1335667</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12294</td>\n",
       "      <td>13678</td>\n",
       "      <td>4</td>\n",
       "      <td>ELEC</td>\n",
       "      <td>1994</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>31/12/1994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-07-13</td>\n",
       "      <td>11</td>\n",
       "      <td>1335667</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14747</td>\n",
       "      <td>14849</td>\n",
       "      <td>4</td>\n",
       "      <td>ELEC</td>\n",
       "      <td>1994</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>31/12/1994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-11-17</td>\n",
       "      <td>11</td>\n",
       "      <td>1335667</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15066</td>\n",
       "      <td>15638</td>\n",
       "      <td>12</td>\n",
       "      <td>ELEC</td>\n",
       "      <td>1994</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>31/12/1994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>11</td>\n",
       "      <td>1335667</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15638</td>\n",
       "      <td>15952</td>\n",
       "      <td>8</td>\n",
       "      <td>ELEC</td>\n",
       "      <td>1994</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   disrict       client_id  client_catg  region creation_date  target  \\\n",
       "0       60  train_Client_0           11     101    31/12/1994     0.0   \n",
       "1       60  train_Client_0           11     101    31/12/1994     0.0   \n",
       "3       60  train_Client_0           11     101    31/12/1994     0.0   \n",
       "4       60  train_Client_0           11     101    31/12/1994     0.0   \n",
       "5       60  train_Client_0           11     101    31/12/1994     0.0   \n",
       "\n",
       "  invoice_date  tarif_type  counter_number  counter_statue  ...  \\\n",
       "0   2014-03-24          11         1335667               0  ...   \n",
       "1   2013-03-29          11         1335667               0  ...   \n",
       "3   2015-07-13          11         1335667               0  ...   \n",
       "4   2016-11-17          11         1335667               0  ...   \n",
       "5   2017-07-17          11         1335667               0  ...   \n",
       "\n",
       "   consommation_level_3  consommation_level_4  old_index  new_index  \\\n",
       "0                     0                     0      14302      14384   \n",
       "1                     0                     0      12294      13678   \n",
       "3                     0                     0      14747      14849   \n",
       "4                     0                     0      15066      15638   \n",
       "5                     0                     0      15638      15952   \n",
       "\n",
       "   months_number  counter_type  year_created  invoice_year  invoice_month  \\\n",
       "0              4          ELEC          1994          2014              3   \n",
       "1              4          ELEC          1994          2013              3   \n",
       "3              4          ELEC          1994          2015              7   \n",
       "4             12          ELEC          1994          2016             11   \n",
       "5              8          ELEC          1994          2017              7   \n",
       "\n",
       "   invoice_weekday  \n",
       "0                0  \n",
       "1                4  \n",
       "3                0  \n",
       "4                3  \n",
       "5                0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451b67e1",
   "metadata": {},
   "source": [
    "### features to use:\n",
    "\n",
    "* client_catg  - yes?\n",
    "* region\n",
    "* tarif_type\n",
    "\n",
    "* counter_number - ?\n",
    "* counter_statue\n",
    "* counter_code - defenitely\n",
    "* reading_remarque - yes\n",
    "* counter_coefficient - maybe\n",
    "\n",
    "* consommation_level_1 ... consommation_level_4 - YES (baseline model)\n",
    "* new_index - ?\n",
    "* months_number - ? (did a lot of exploration - difficult to decide)\n",
    "* counter_type - probably yes (common sence / domain knowledge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28311588",
   "metadata": {},
   "source": [
    "### features to omit:\n",
    "\n",
    "* disrict (this information is dependent on 'region' and is \"stored\" there already)\n",
    "* client_id\n",
    "* creation_date - ?\n",
    "* invoice_date (feature engineer month / year?)\n",
    "* old_index (almost perfectly correlates with 'new_index')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034c4d3b",
   "metadata": {},
   "source": [
    "### features to engineer:\n",
    "\n",
    "* month\n",
    "* year ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b6d956",
   "metadata": {},
   "source": [
    "## The first quick and dirty model (logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c333242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['disrict', 'client_id', 'client_catg', 'region', 'creation_date',\n",
       "       'target', 'invoice_date', 'tarif_type', 'counter_number',\n",
       "       'counter_statue', 'counter_code', 'reading_remarque',\n",
       "       'counter_coefficient', 'consommation_level_1', 'consommation_level_2',\n",
       "       'consommation_level_3', 'consommation_level_4', 'old_index',\n",
       "       'new_index', 'months_number', 'counter_type', 'year_created',\n",
       "       'invoice_year', 'invoice_month', 'invoice_weekday'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a5d2893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter_number 201893\n",
      "consommation_level_1 8295\n",
      "consommation_level_2 12576\n",
      "consommation_level_3 2253\n",
      "consommation_level_4 12075\n",
      "new_index 157980\n",
      "months_number 1370\n"
     ]
    }
   ],
   "source": [
    "# treat these as continuous (i.e. scale them) or bin them (?)\n",
    "discrete_features = ['counter_number', 'consommation_level_1', 'consommation_level_2',\n",
    "       'consommation_level_3', 'consommation_level_4', 'new_index', 'months_number']\n",
    "\n",
    "for col in discrete_features:\n",
    "    print(col, df[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "182636bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_catg 3\n",
      "region 25\n",
      "tarif_type 17\n",
      "counter_statue 6\n",
      "counter_code 42\n",
      "reading_remarque 8\n",
      "counter_coefficient 16\n",
      "counter_type 2\n",
      "year_created 43\n",
      "invoice_year 43\n",
      "invoice_month 12\n",
      "invoice_weekday 7\n"
     ]
    }
   ],
   "source": [
    "# these categorical features have 43 unique value or less (dummyfy them)\n",
    "cat_features = ['client_catg', 'region', 'tarif_type',\n",
    "       'counter_statue', 'counter_code', 'reading_remarque',\n",
    "       'counter_coefficient', 'counter_type', 'year_created',   # counter_type = object?\n",
    "       'invoice_year', 'invoice_month', 'invoice_weekday']\n",
    "\n",
    "for col in cat_features:\n",
    "    print(col, df[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04645fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale\n",
    "df_scaled = (df[discrete_features] - df[discrete_features].mean(axis=0)) / df[discrete_features].std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afe9f4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummyfy\n",
    "df_dummy = pd.get_dummies(df[cat_features], drop_first=True, columns=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "689bf7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate\n",
    "df_prep = pd.concat([df_scaled, df_dummy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e9b8c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the X,y for sklearn input\n",
    "X = df_prep.values\n",
    "y = df['target'].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "412fb5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: [0.128 0.124 0.139 0.124 0.111] 0.125\n",
      "f2: [0.085 0.082 0.093 0.082 0.073] 0.083\n",
      "AUC = 0.7480235750605515\n"
     ]
    }
   ],
   "source": [
    "# build a model\n",
    "\n",
    "\n",
    "######################################\n",
    "# random sample\n",
    "m = 100_000\n",
    "nx = np.random.permutation(len(y))[:m]\n",
    "\n",
    "X = df_prep.values\n",
    "y = df['target'].values.astype(int)\n",
    "\n",
    "X = X[nx]\n",
    "y = ytrue = y[nx]\n",
    "####################################\n",
    "\n",
    "\n",
    "md = LogisticRegression(solver='newton-cholesky', max_iter=500)\n",
    "\n",
    "ypred = cross_val_predict(md, X,y, cv=5)\n",
    "\n",
    "\n",
    "# f1\n",
    "f1 = cross_val_score(md, X,y, scoring='f1', cv=5)\n",
    "print(\"f1:\", f1.round(3), f1.mean().round(3))\n",
    "\n",
    "# f2\n",
    "scorer = make_scorer(fbeta_score, beta=2)\n",
    "f2 = cross_val_score(md, X,y, scoring=scorer, cv=5)\n",
    "print(\"f2:\", f2.round(3), f2.mean().round(3))\n",
    "\n",
    "# AUC\n",
    "ppred = cross_val_predict(md, X,y, cv=5, method='predict_proba')[:,-1]\n",
    "auc = roc_auc_score(ytrue, ppred)\n",
    "print(\"AUC =\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9769569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     91824\n",
      "           1       0.83      0.07      0.13      8176\n",
      "\n",
      "    accuracy                           0.92    100000\n",
      "   macro avg       0.88      0.53      0.54    100000\n",
      "weighted avg       0.92      0.92      0.89    100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytrue, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c61e6154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[91710,   114],\n",
       "       [ 7622,   554]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(ytrue, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6838a206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741b0679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17481ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca7140c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
